AWSTemplateFormatVersion: '2010-09-09'
Parameters:
  Environment:
    Type: String
    Default: dev

Resources:
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource: 
                  - !Sub 'arn:aws:s3:::pdf-input-${Environment}-${AWS::AccountId}-${AWS::Region}/*'
                  - !Sub 'arn:aws:s3:::pdf-output-${Environment}-${AWS::AccountId}-${AWS::Region}/*'
        - PolicyName: DynamoDBAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:PutItem
                  - dynamodb:GetItem
                  - dynamodb:UpdateItem
                Resource: !Sub 'arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/pdf-processing-${Environment}'
        - PolicyName: LambdaInvoke
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource: !Sub 'arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:*-processor-${Environment}'
        - PolicyName: TextractAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - textract:DetectDocumentText
                  - textract:AnalyzeDocument
                Resource: '*'

  # Router Lambda - Enhanced with better logging
  DocumentRouter:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'document-router-${Environment}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          import os
          from datetime import datetime
          
          lambda_client = boto3.client('lambda')
          dynamodb = boto3.resource('dynamodb')
          
          def lambda_handler(event, context):
              print(f"Router Event: {json.dumps(event, indent=2)}")
              
              function_name = context.function_name
              env = function_name.split('-')[-1]
              
              table_name = f'pdf-processing-{env}'
              table = dynamodb.Table(table_name)
              
              print(f"Using DynamoDB table: {table_name}")
              
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  
                  print(f"Processing file: {key} from bucket: {bucket}")
                  
                  # Log initial routing
                  try:
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'ROUTING',
                          'timestamp': datetime.now().isoformat(),
                          'bucket': bucket
                      })
                      print(f"Logged ROUTING status for {key}")
                  except Exception as e:
                      print(f"Error logging to DynamoDB: {str(e)}")
                  
                  # Determine processor based on file extension
                  file_ext = key.lower().split('.')[-1] if '.' in key else 'unknown'
                  print(f"File extension detected: {file_ext}")
                  
                  processor_map = {
                      'pdf': f'pdf-processor-{env}',
                      'csv': f'csv-processor-{env}',
                      'txt': f'text-processor-{env}',
                      'md': f'text-processor-{env}'
                  }
                  
                  processor_function = processor_map.get(file_ext)
                  print(f"Selected processor: {processor_function}")
                  
                  if processor_function:
                      try:
                          print(f"Invoking {processor_function} for {key}")
                          
                          # Invoke specific processor
                          response = lambda_client.invoke(
                              FunctionName=processor_function,
                              InvocationType='Event',  # Async
                              Payload=json.dumps(event)
                          )
                          
                          print(f"Lambda invoke response: {response}")
                          
                          table.put_item(Item={
                              'file_key': key,
                              'status': 'ROUTED',
                              'timestamp': datetime.now().isoformat(),
                              'bucket': bucket,
                              'processor': processor_function
                          })
                          
                          print(f"Successfully routed {key} to {processor_function}")
                          
                      except Exception as e:
                          error_msg = str(e)
                          print(f"Routing error for {key}: {error_msg}")
                          table.put_item(Item={
                              'file_key': key,
                              'status': 'ROUTING_FAILED',
                              'timestamp': datetime.now().isoformat(),
                              'bucket': bucket,
                              'error': error_msg
                          })
                  else:
                      print(f"No processor available for file type: {file_ext}")
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'UNSUPPORTED_TYPE',
                          'timestamp': datetime.now().isoformat(),
                          'bucket': bucket,
                          'file_type': file_ext
                      })
              
              return {"statusCode": 200, "body": "Routing complete"}

  # Text Processor - Enhanced with explicit bucket names and error handling
  TextProcessor:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'text-processor-${Environment}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          from datetime import datetime
          import traceback
          
          s3 = boto3.client('s3')
          dynamodb = boto3.resource('dynamodb')
          
          def lambda_handler(event, context):
              print(f"Text Processor Event: {json.dumps(event, indent=2)}")
              
              function_name = context.function_name
              env = function_name.split('-')[-1]
              
              table_name = f'pdf-processing-{env}'
              table = dynamodb.Table(table_name)
              
              print(f"Using DynamoDB table: {table_name}")
              
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  
                  print(f"Processing text file: {key} from bucket: {bucket}")
                  
                  try:
                      # Log processing start
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'TEXT_PROCESSING',
                          'timestamp': datetime.now().isoformat(),
                          'processor': 'text-processor'
                      })
                      print(f"Logged TEXT_PROCESSING status for {key}")
                      
                      # Read file from S3
                      print(f"Reading file from S3: s3://{bucket}/{key}")
                      response = s3.get_object(Bucket=bucket, Key=key)
                      text_content = response['Body'].read().decode('utf-8')
                      print(f"File read successfully, content length: {len(text_content)}")
                      
                      # Basic text analysis
                      lines = text_content.split('\n')
                      words = text_content.split()
                      
                      analysis = f"Text Analysis for: {key}\n"
                      analysis += f"Characters: {len(text_content)}\n"
                      analysis += f"Lines: {len(lines)}\n"
                      analysis += f"Words: {len(words)}\n"
                      analysis += f"Processed at: {datetime.now().isoformat()}\n"
                      analysis += f"\nContent:\n{text_content}"
                      
                      print(f"Analysis complete - Characters: {len(text_content)}, Words: {len(words)}")
                      
                      # FIXED: Explicit bucket name construction
                      if 'pdf-input-' in bucket:
                          output_bucket = bucket.replace('pdf-input-', 'pdf-output-')
                      else:
                          # Fallback method
                          output_bucket = bucket.replace('input', 'output')
                      
                      output_key = f"text-analyzed/{key}_analysis.txt"
                      
                      print(f"Output bucket: {output_bucket}")
                      print(f"Output key: {output_key}")
                      
                      # Write to S3 output bucket
                      print(f"Writing analysis to S3: s3://{output_bucket}/{output_key}")
                      s3.put_object(
                          Bucket=output_bucket,
                          Key=output_key,
                          Body=analysis,
                          ContentType='text/plain'
                      )
                      print(f"Successfully wrote file to S3")
                      
                      # Log completion
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'TEXT_COMPLETED',
                          'timestamp': datetime.now().isoformat(),
                          'output_bucket': output_bucket,
                          'output_key': output_key,
                          'word_count': len(words),
                          'processor': 'text-processor'
                      })
                      
                      print(f"Successfully processed {key}")
                      
                  except Exception as e:
                      error_msg = str(e)
                      print(f"Error processing {key}: {error_msg}")
                      print(f"Traceback: {traceback.format_exc()}")
                      
                      try:
                          table.put_item(Item={
                              'file_key': key,
                              'status': 'TEXT_FAILED',
                              'timestamp': datetime.now().isoformat(),
                              'error': error_msg,
                              'processor': 'text-processor'
                          })
                      except Exception as db_error:
                          print(f"Failed to log error to DynamoDB: {str(db_error)}")
              
              return {"statusCode": 200, "body": "Text processing complete"}

  # CSV Processor - Enhanced with explicit bucket names and error handling  
  CSVProcessor:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'csv-processor-${Environment}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaRole.Arn
      Code:
        ZipFile: |
          import json
          import boto3
          import csv
          import io
          from datetime import datetime
          import traceback
          
          s3 = boto3.client('s3')
          dynamodb = boto3.resource('dynamodb')
          
          def lambda_handler(event, context):
              print(f"CSV Processor Event: {json.dumps(event, indent=2)}")
              
              function_name = context.function_name
              env = function_name.split('-')[-1]
              
              table_name = f'pdf-processing-{env}'
              table = dynamodb.Table(table_name)
              
              print(f"Using DynamoDB table: {table_name}")
              
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  
                  print(f"Processing CSV file: {key} from bucket: {bucket}")
                  
                  try:
                      # Log processing start
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'CSV_PROCESSING',
                          'timestamp': datetime.now().isoformat(),
                          'processor': 'csv-processor'
                      })
                      print(f"Logged CSV_PROCESSING status for {key}")
                      
                      # Read CSV from S3
                      print(f"Reading CSV from S3: s3://{bucket}/{key}")
                      response = s3.get_object(Bucket=bucket, Key=key)
                      csv_content = response['Body'].read().decode('utf-8')
                      print(f"CSV read successfully, content length: {len(csv_content)}")
                      
                      # Parse CSV and create summary
                      csv_reader = csv.reader(io.StringIO(csv_content))
                      rows = list(csv_reader)
                      
                      summary = f"CSV Analysis for: {key}\n"
                      summary += f"Processed at: {datetime.now().isoformat()}\n"
                      summary += f"Total rows: {len(rows)}\n"
                      if rows:
                          summary += f"Columns: {len(rows[0])}\n"
                          summary += f"Headers: {', '.join(rows[0])}\n"
                          summary += f"\nFirst 5 rows:\n"
                          for i, row in enumerate(rows[:6]):  # Header + 5 rows
                              summary += f"Row {i}: {', '.join(row)}\n"
                      
                      print(f"CSV analysis complete - Rows: {len(rows)}")
                      
                      # FIXED: Explicit bucket name construction
                      if 'pdf-input-' in bucket:
                          output_bucket = bucket.replace('pdf-input-', 'pdf-output-')
                      else:
                          output_bucket = bucket.replace('input', 'output')
                      
                      output_key = f"csv-analyzed/{key}_summary.txt"
                      
                      print(f"Output bucket: {output_bucket}")
                      print(f"Output key: {output_key}")
                      
                      # Write to S3
                      print(f"Writing summary to S3: s3://{output_bucket}/{output_key}")
                      s3.put_object(
                          Bucket=output_bucket,
                          Key=output_key,
                          Body=summary,
                          ContentType='text/plain'
                      )
                      print(f"Successfully wrote CSV summary to S3")
                      
                      # Log completion
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'CSV_COMPLETED',
                          'timestamp': datetime.now().isoformat(),
                          'output_bucket': output_bucket,
                          'output_key': output_key,
                          'row_count': len(rows),
                          'processor': 'csv-processor'
                      })
                      
                      print(f"Successfully processed CSV {key}")
                      
                  except Exception as e:
                      error_msg = str(e)
                      print(f"Error processing CSV {key}: {error_msg}")
                      print(f"Traceback: {traceback.format_exc()}")
                      
                      try:
                          table.put_item(Item={
                              'file_key': key,
                              'status': 'CSV_FAILED',
                              'timestamp': datetime.now().isoformat(),
                              'error': error_msg,
                              'processor': 'csv-processor'
                          })
                      except Exception as db_error:
                          print(f"Failed to log error to DynamoDB: {str(db_error)}")
              
              return {"statusCode": 200, "body": "CSV processing complete"}

  # PDF Processor - With AWS Textract integration for real text extraction
  PDFProcessor:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub 'pdf-processor-${Environment}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt LambdaRole.Arn
      Timeout: 300
      MemorySize: 1024
      Code:
        ZipFile: |
          import json
          import boto3
          from datetime import datetime
          import traceback
          
          s3 = boto3.client('s3')
          dynamodb = boto3.resource('dynamodb')
          textract = boto3.client('textract')
          
          def lambda_handler(event, context):
              print(f"PDF Processor Event: {json.dumps(event, indent=2)}")
              
              function_name = context.function_name
              env = function_name.split('-')[-1]
              
              table_name = f'pdf-processing-{env}'
              table = dynamodb.Table(table_name)
              
              print(f"Using DynamoDB table: {table_name}")
              
              for record in event['Records']:
                  bucket = record['s3']['bucket']['name']
                  key = record['s3']['object']['key']
                  
                  print(f"Processing PDF file: {key} from bucket: {bucket}")
                  
                  try:
                      # Log processing start
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'PDF_PROCESSING',
                          'timestamp': datetime.now().isoformat(),
                          'processor': 'pdf-processor'
                      })
                      print(f"Logged PDF_PROCESSING status for {key}")
                      
                      # Use AWS Textract to extract text from PDF
                      print(f"Starting Textract text detection for s3://{bucket}/{key}")
                      
                      textract_response = textract.detect_document_text(
                          Document={
                              'S3Object': {
                                  'Bucket': bucket,
                                  'Name': key
                              }
                          }
                      )
                      
                      print(f"Textract response received, found {len(textract_response.get('Blocks', []))} blocks")
                      
                      # Extract text from Textract response
                      extracted_text = ""
                      line_text = []
                      
                      for block in textract_response.get('Blocks', []):
                          if block['BlockType'] == 'LINE':
                              line_text.append(block.get('Text', ''))
                      
                      extracted_text = '\n'.join(line_text)
                      
                      # Create analysis report
                      analysis = f"PDF Text Extraction for: {key}\n"
                      analysis += f"Processed at: {datetime.now().isoformat()}\n"
                      analysis += f"Extraction method: AWS Textract\n"
                      analysis += f"Text blocks found: {len(textract_response.get('Blocks', []))}\n"
                      analysis += f"Lines of text: {len(line_text)}\n"
                      analysis += f"Characters extracted: {len(extracted_text)}\n"
                      analysis += f"Words extracted: {len(extracted_text.split())}\n"
                      analysis += f"\n{'='*50}\n"
                      analysis += f"EXTRACTED TEXT:\n"
                      analysis += f"{'='*50}\n"
                      analysis += extracted_text
                      
                      print(f"Text extraction complete - Characters: {len(extracted_text)}, Lines: {len(line_text)}")
                      
                      # FIXED: Explicit bucket name construction
                      if 'pdf-input-' in bucket:
                          output_bucket = bucket.replace('pdf-input-', 'pdf-output-')
                      else:
                          output_bucket = bucket.replace('input', 'output')
                      
                      output_key = f"pdf-extracted/{key}_text.txt"
                      
                      print(f"Output bucket: {output_bucket}")
                      print(f"Output key: {output_key}")
                      
                      # Write to S3
                      print(f"Writing extracted text to S3: s3://{output_bucket}/{output_key}")
                      s3.put_object(
                          Bucket=output_bucket,
                          Key=output_key,
                          Body=analysis,
                          ContentType='text/plain'
                      )
                      print(f"Successfully wrote PDF text extraction to S3")
                      
                      # Log completion
                      table.put_item(Item={
                          'file_key': key,
                          'status': 'PDF_COMPLETED',
                          'timestamp': datetime.now().isoformat(),
                          'output_bucket': output_bucket,
                          'output_key': output_key,
                          'processor': 'pdf-processor',
                          'extraction_method': 'textract',
                          'characters_extracted': len(extracted_text),
                          'lines_extracted': len(line_text)
                      })
                      
                      print(f"Successfully processed PDF {key} with Textract")
                      
                  except Exception as e:
                      error_msg = str(e)
                      print(f"Error processing PDF {key}: {error_msg}")
                      print(f"Traceback: {traceback.format_exc()}")
                      
                      try:
                          table.put_item(Item={
                              'file_key': key,
                              'status': 'PDF_FAILED',
                              'timestamp': datetime.now().isoformat(),
                              'error': error_msg,
                              'processor': 'pdf-processor'
                          })
                      except Exception as db_error:
                          print(f"Failed to log error to DynamoDB: {str(db_error)}")
              
              return {"statusCode": 200, "body": "PDF processing complete"}

Outputs:
  DocumentRouter:
    Value: !Ref DocumentRouter
    Export:
      Name: !Sub '${AWS::StackName}-DocumentRouter'
  PDFProcessor:
    Value: !Ref PDFProcessor
    Export:
      Name: !Sub '${AWS::StackName}-PDFProcessor'
  CSVProcessor:
    Value: !Ref CSVProcessor
    Export:
      Name: !Sub '${AWS::StackName}-CSVProcessor'
  TextProcessor:
    Value: !Ref TextProcessor
    Export:
      Name: !Sub '${AWS::StackName}-TextProcessor'